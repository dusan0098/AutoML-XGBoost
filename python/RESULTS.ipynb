{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTEBOOK SHOWCASING RESULTS OF ALL METHODS USED IN THE PROJECT\n",
    "\n",
    "For more details on the implementation of each method, please look at the respective .py files:\n",
    "    1) Direct regression - compare_regressors.py\n",
    "    2) Taskwise regression - taskRegression.py\n",
    "    3) Joint regression - fullDataRegression.py\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from python.project_utils import training_meta_features, hyperparameters_data\n",
    "from IPython.core.display_functions import display\n",
    "from python.compare_regressors import compare_regressor_with_baseline, evaluate_bayesian_regressors\n",
    "from sklearn import ensemble\n",
    "from python.taskRegression import evaluate_taskwise_regression\n",
    "from python.fullDataRegression import evaluate_full_data_regression\n",
    "\n",
    "\n",
    "#Metadata for train and test datasets\n",
    "meta_train = pd.read_csv('./data/features.csv')\n",
    "meta_test = pd.read_csv('./data/test_features.csv')\n",
    "#Aggregated xgboost evaluation data\n",
    "avg_performance = pd.read_csv('./data/average_performance.csv')\n",
    "\n",
    "#Performance achieved on test datasets with default configuration\n",
    "baseline = pd.read_csv('./data/baseline_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This cell contains the results of the Direct Regression of Hyperparameters approach from the project report\n",
    "\"\"\"\n",
    "\"\"\" 1.Results of different regressors without HPO\"\"\"\n",
    "\n",
    "#Gradient boosting\n",
    "gb_results_default = pd.read_csv('./data/gradient_boosting_comparison.csv')\n",
    "#Random forest\n",
    "rf_results_default = pd.read_csv('./data/random_forest_comparison.csv')\n",
    "#Fully connected neural net - defined in FFN_regression.py\n",
    "ffn_results_default = pd.read_csv('./data/neural_net.csv')\n",
    "#Multilayer perceptron\n",
    "mlperceptron_results_default = pd.read_csv('./data/mlperceptron_default.csv')\n",
    "#KNeigbour\n",
    "knn_results_default = pd.read_csv('./data/kmeans_default.csv')\n",
    "\n",
    "\"\"\" 2.Results of different regressors with HPO using Bayesian Optimisation\"\"\"\n",
    "\n",
    "#XGBoost regressor\n",
    "xgboost_results_bayes = pd.read_csv('./data/bayes_xgboost_result.csv')\n",
    "#Random forest\n",
    "rf_results_bayes = pd.read_csv('./data/bayes_rforest.csv')\n",
    "#KNeighbour\n",
    "knn_results_bayes = pd.read_csv('./data/bayes_knn_results.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This cell contains the results of the Indirect Regression of Hyperparameters through modeling AUC\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    1. Taskwise regression - 94 xgboost models trained on separate training datasets. Their predictions are\n",
    "    weighted based on the similarity of the training dataset whose evaluation data was used to the new dataset\n",
    "\"\"\"\n",
    "xgboost_results_taskwise_regression = pd.read_csv('./data/weighted_taskwise_regression_performance.csv')\n",
    "\n",
    "\"\"\"\n",
    "     2. Joint regression - a single model was trained on 15% (100.000rows) of the average performance data.\n",
    "     This model takes both the metafeatures and hyperparameters as input and predicts the AUC\n",
    "\n",
    "     A second layer of regression was added using a Guassian Process to fit the first models predictions, but the minimisation function\n",
    "     can't move from a local minimum for a small number of points. For a large number of points fitting the GP to the predictions takes too long\n",
    "\"\"\"\n",
    "xgboost_results_joint_regression = pd.read_csv('./data/fulldata_nested_xgboost_results.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2792acdadc0>",
      "text/html": "<style type=\"text/css\">\n#T_91a3b_row0_col1, #T_91a3b_row0_col2, #T_91a3b_row0_col7, #T_91a3b_row0_col11, #T_91a3b_row1_col11, #T_91a3b_row1_col13, #T_91a3b_row1_col15, #T_91a3b_row2_col4, #T_91a3b_row2_col11, #T_91a3b_row3_col11, #T_91a3b_row5_col11, #T_91a3b_row5_col16, #T_91a3b_row6_col11, #T_91a3b_row7_col3, #T_91a3b_row7_col11, #T_91a3b_row8_col0, #T_91a3b_row8_col6, #T_91a3b_row8_col11, #T_91a3b_row8_col14, #T_91a3b_row9_col5, #T_91a3b_row9_col8, #T_91a3b_row9_col9, #T_91a3b_row9_col10, #T_91a3b_row9_col11, #T_91a3b_row9_col12, #T_91a3b_row10_col11, #T_91a3b_row10_col17 {\n  background-color: lightgreen;\n}\n#T_91a3b_row0_col10, #T_91a3b_row3_col8, #T_91a3b_row3_col9, #T_91a3b_row4_col0, #T_91a3b_row4_col1, #T_91a3b_row4_col2, #T_91a3b_row4_col3, #T_91a3b_row4_col4, #T_91a3b_row4_col6, #T_91a3b_row4_col7, #T_91a3b_row4_col11, #T_91a3b_row4_col12, #T_91a3b_row4_col13, #T_91a3b_row4_col14, #T_91a3b_row4_col15, #T_91a3b_row4_col16, #T_91a3b_row4_col17, #T_91a3b_row10_col5 {\n  background-color: orange;\n}\n</style>\n<table id=\"T_91a3b_\">\n  <thead>\n    <tr>\n      <th class=\"index_name level0\" >task_id</th>\n      <th class=\"col_heading level0 col0\" >16</th>\n      <th class=\"col_heading level0 col1\" >22</th>\n      <th class=\"col_heading level0 col2\" >31</th>\n      <th class=\"col_heading level0 col3\" >2074</th>\n      <th class=\"col_heading level0 col4\" >2079</th>\n      <th class=\"col_heading level0 col5\" >3493</th>\n      <th class=\"col_heading level0 col6\" >3907</th>\n      <th class=\"col_heading level0 col7\" >3913</th>\n      <th class=\"col_heading level0 col8\" >9950</th>\n      <th class=\"col_heading level0 col9\" >9952</th>\n      <th class=\"col_heading level0 col10\" >9971</th>\n      <th class=\"col_heading level0 col11\" >10106</th>\n      <th class=\"col_heading level0 col12\" >14954</th>\n      <th class=\"col_heading level0 col13\" >14970</th>\n      <th class=\"col_heading level0 col14\" >146212</th>\n      <th class=\"col_heading level0 col15\" >168336</th>\n      <th class=\"col_heading level0 col16\" >167125</th>\n      <th class=\"col_heading level0 col17\" >167119</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_91a3b_level0_row0\" class=\"row_heading level0 row0\" >baseline</th>\n      <td id=\"T_91a3b_row0_col0\" class=\"data row0 col0\" >0.997222</td>\n      <td id=\"T_91a3b_row0_col1\" class=\"data row0 col1\" >0.973361</td>\n      <td id=\"T_91a3b_row0_col2\" class=\"data row0 col2\" >0.841905</td>\n      <td id=\"T_91a3b_row0_col3\" class=\"data row0 col3\" >0.989416</td>\n      <td id=\"T_91a3b_row0_col4\" class=\"data row0 col4\" >0.915436</td>\n      <td id=\"T_91a3b_row0_col5\" class=\"data row0 col5\" >0.976190</td>\n      <td id=\"T_91a3b_row0_col6\" class=\"data row0 col6\" >0.985866</td>\n      <td id=\"T_91a3b_row0_col7\" class=\"data row0 col7\" >0.906926</td>\n      <td id=\"T_91a3b_row0_col8\" class=\"data row0 col8\" >0.996221</td>\n      <td id=\"T_91a3b_row0_col9\" class=\"data row0 col9\" >0.956024</td>\n      <td id=\"T_91a3b_row0_col10\" class=\"data row0 col10\" >0.668067</td>\n      <td id=\"T_91a3b_row0_col11\" class=\"data row0 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row0_col12\" class=\"data row0 col12\" >0.910238</td>\n      <td id=\"T_91a3b_row0_col13\" class=\"data row0 col13\" >0.999844</td>\n      <td id=\"T_91a3b_row0_col14\" class=\"data row0 col14\" >0.999998</td>\n      <td id=\"T_91a3b_row0_col15\" class=\"data row0 col15\" >0.735831</td>\n      <td id=\"T_91a3b_row0_col16\" class=\"data row0 col16\" >0.962805</td>\n      <td id=\"T_91a3b_row0_col17\" class=\"data row0 col17\" >0.969022</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row1\" class=\"row_heading level0 row1\" >GB default</th>\n      <td id=\"T_91a3b_row1_col0\" class=\"data row1 col0\" >0.997889</td>\n      <td id=\"T_91a3b_row1_col1\" class=\"data row1 col1\" >0.967194</td>\n      <td id=\"T_91a3b_row1_col2\" class=\"data row1 col2\" >0.807143</td>\n      <td id=\"T_91a3b_row1_col3\" class=\"data row1 col3\" >0.991453</td>\n      <td id=\"T_91a3b_row1_col4\" class=\"data row1 col4\" >0.922794</td>\n      <td id=\"T_91a3b_row1_col5\" class=\"data row1 col5\" >0.720238</td>\n      <td id=\"T_91a3b_row1_col6\" class=\"data row1 col6\" >0.908131</td>\n      <td id=\"T_91a3b_row1_col7\" class=\"data row1 col7\" >0.867965</td>\n      <td id=\"T_91a3b_row1_col8\" class=\"data row1 col8\" >0.994527</td>\n      <td id=\"T_91a3b_row1_col9\" class=\"data row1 col9\" >0.956815</td>\n      <td id=\"T_91a3b_row1_col10\" class=\"data row1 col10\" >0.698880</td>\n      <td id=\"T_91a3b_row1_col11\" class=\"data row1 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row1_col12\" class=\"data row1 col12\" >0.886396</td>\n      <td id=\"T_91a3b_row1_col13\" class=\"data row1 col13\" >0.999983</td>\n      <td id=\"T_91a3b_row1_col14\" class=\"data row1 col14\" >0.999985</td>\n      <td id=\"T_91a3b_row1_col15\" class=\"data row1 col15\" >0.759066</td>\n      <td id=\"T_91a3b_row1_col16\" class=\"data row1 col16\" >0.953477</td>\n      <td id=\"T_91a3b_row1_col17\" class=\"data row1 col17\" >0.974388</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row2\" class=\"row_heading level0 row2\" >RF default</th>\n      <td id=\"T_91a3b_row2_col0\" class=\"data row2 col0\" >0.998139</td>\n      <td id=\"T_91a3b_row2_col1\" class=\"data row2 col1\" >0.969611</td>\n      <td id=\"T_91a3b_row2_col2\" class=\"data row2 col2\" >0.808095</td>\n      <td id=\"T_91a3b_row2_col3\" class=\"data row2 col3\" >0.991936</td>\n      <td id=\"T_91a3b_row2_col4\" class=\"data row2 col4\" >0.929316</td>\n      <td id=\"T_91a3b_row2_col5\" class=\"data row2 col5\" >0.877381</td>\n      <td id=\"T_91a3b_row2_col6\" class=\"data row2 col6\" >0.915198</td>\n      <td id=\"T_91a3b_row2_col7\" class=\"data row2 col7\" >0.893939</td>\n      <td id=\"T_91a3b_row2_col8\" class=\"data row2 col8\" >0.993560</td>\n      <td id=\"T_91a3b_row2_col9\" class=\"data row2 col9\" >0.956765</td>\n      <td id=\"T_91a3b_row2_col10\" class=\"data row2 col10\" >0.735294</td>\n      <td id=\"T_91a3b_row2_col11\" class=\"data row2 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row2_col12\" class=\"data row2 col12\" >0.918654</td>\n      <td id=\"T_91a3b_row2_col13\" class=\"data row2 col13\" >0.999974</td>\n      <td id=\"T_91a3b_row2_col14\" class=\"data row2 col14\" >0.999993</td>\n      <td id=\"T_91a3b_row2_col15\" class=\"data row2 col15\" >0.749506</td>\n      <td id=\"T_91a3b_row2_col16\" class=\"data row2 col16\" >0.954132</td>\n      <td id=\"T_91a3b_row2_col17\" class=\"data row2 col17\" >0.976131</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row3\" class=\"row_heading level0 row3\" >FFN default</th>\n      <td id=\"T_91a3b_row3_col0\" class=\"data row3 col0\" >0.994778</td>\n      <td id=\"T_91a3b_row3_col1\" class=\"data row3 col1\" >0.972806</td>\n      <td id=\"T_91a3b_row3_col2\" class=\"data row3 col2\" >0.816190</td>\n      <td id=\"T_91a3b_row3_col3\" class=\"data row3 col3\" >0.985266</td>\n      <td id=\"T_91a3b_row3_col4\" class=\"data row3 col4\" >0.900401</td>\n      <td id=\"T_91a3b_row3_col5\" class=\"data row3 col5\" >0.814286</td>\n      <td id=\"T_91a3b_row3_col6\" class=\"data row3 col6\" >0.893693</td>\n      <td id=\"T_91a3b_row3_col7\" class=\"data row3 col7\" >0.849567</td>\n      <td id=\"T_91a3b_row3_col8\" class=\"data row3 col8\" >0.987380</td>\n      <td id=\"T_91a3b_row3_col9\" class=\"data row3 col9\" >0.910830</td>\n      <td id=\"T_91a3b_row3_col10\" class=\"data row3 col10\" >0.733894</td>\n      <td id=\"T_91a3b_row3_col11\" class=\"data row3 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row3_col12\" class=\"data row3 col12\" >0.875175</td>\n      <td id=\"T_91a3b_row3_col13\" class=\"data row3 col13\" >0.999727</td>\n      <td id=\"T_91a3b_row3_col14\" class=\"data row3 col14\" >0.999977</td>\n      <td id=\"T_91a3b_row3_col15\" class=\"data row3 col15\" >0.725424</td>\n      <td id=\"T_91a3b_row3_col16\" class=\"data row3 col16\" >0.944110</td>\n      <td id=\"T_91a3b_row3_col17\" class=\"data row3 col17\" >0.925409</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row4\" class=\"row_heading level0 row4\" >MLP default</th>\n      <td id=\"T_91a3b_row4_col0\" class=\"data row4 col0\" >0.988417</td>\n      <td id=\"T_91a3b_row4_col1\" class=\"data row4 col1\" >0.960611</td>\n      <td id=\"T_91a3b_row4_col2\" class=\"data row4 col2\" >0.800000</td>\n      <td id=\"T_91a3b_row4_col3\" class=\"data row4 col3\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col4\" class=\"data row4 col4\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col5\" class=\"data row4 col5\" >0.575000</td>\n      <td id=\"T_91a3b_row4_col6\" class=\"data row4 col6\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col7\" class=\"data row4 col7\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col8\" class=\"data row4 col8\" >0.996702</td>\n      <td id=\"T_91a3b_row4_col9\" class=\"data row4 col9\" >0.920371</td>\n      <td id=\"T_91a3b_row4_col10\" class=\"data row4 col10\" >0.733894</td>\n      <td id=\"T_91a3b_row4_col11\" class=\"data row4 col11\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col12\" class=\"data row4 col12\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col13\" class=\"data row4 col13\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col14\" class=\"data row4 col14\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col15\" class=\"data row4 col15\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col16\" class=\"data row4 col16\" >0.500000</td>\n      <td id=\"T_91a3b_row4_col17\" class=\"data row4 col17\" >0.500000</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row5\" class=\"row_heading level0 row5\" >KNN default</th>\n      <td id=\"T_91a3b_row5_col0\" class=\"data row5 col0\" >0.997250</td>\n      <td id=\"T_91a3b_row5_col1\" class=\"data row5 col1\" >0.968194</td>\n      <td id=\"T_91a3b_row5_col2\" class=\"data row5 col2\" >0.840000</td>\n      <td id=\"T_91a3b_row5_col3\" class=\"data row5 col3\" >0.991432</td>\n      <td id=\"T_91a3b_row5_col4\" class=\"data row5 col4\" >0.910252</td>\n      <td id=\"T_91a3b_row5_col5\" class=\"data row5 col5\" >0.989286</td>\n      <td id=\"T_91a3b_row5_col6\" class=\"data row5 col6\" >0.924772</td>\n      <td id=\"T_91a3b_row5_col7\" class=\"data row5 col7\" >0.846320</td>\n      <td id=\"T_91a3b_row5_col8\" class=\"data row5 col8\" >0.996575</td>\n      <td id=\"T_91a3b_row5_col9\" class=\"data row5 col9\" >0.958280</td>\n      <td id=\"T_91a3b_row5_col10\" class=\"data row5 col10\" >0.703081</td>\n      <td id=\"T_91a3b_row5_col11\" class=\"data row5 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row5_col12\" class=\"data row5 col12\" >0.918654</td>\n      <td id=\"T_91a3b_row5_col13\" class=\"data row5 col13\" >0.999974</td>\n      <td id=\"T_91a3b_row5_col14\" class=\"data row5 col14\" >0.999997</td>\n      <td id=\"T_91a3b_row5_col15\" class=\"data row5 col15\" >0.737038</td>\n      <td id=\"T_91a3b_row5_col16\" class=\"data row5 col16\" >0.971785</td>\n      <td id=\"T_91a3b_row5_col17\" class=\"data row5 col17\" >0.973041</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row6\" class=\"row_heading level0 row6\" >RF with BO</th>\n      <td id=\"T_91a3b_row6_col0\" class=\"data row6 col0\" >0.997917</td>\n      <td id=\"T_91a3b_row6_col1\" class=\"data row6 col1\" >0.966778</td>\n      <td id=\"T_91a3b_row6_col2\" class=\"data row6 col2\" >0.805238</td>\n      <td id=\"T_91a3b_row6_col3\" class=\"data row6 col3\" >0.991691</td>\n      <td id=\"T_91a3b_row6_col4\" class=\"data row6 col4\" >0.928377</td>\n      <td id=\"T_91a3b_row6_col5\" class=\"data row6 col5\" >0.927381</td>\n      <td id=\"T_91a3b_row6_col6\" class=\"data row6 col6\" >0.913070</td>\n      <td id=\"T_91a3b_row6_col7\" class=\"data row6 col7\" >0.893939</td>\n      <td id=\"T_91a3b_row6_col8\" class=\"data row6 col8\" >0.993721</td>\n      <td id=\"T_91a3b_row6_col9\" class=\"data row6 col9\" >0.956880</td>\n      <td id=\"T_91a3b_row6_col10\" class=\"data row6 col10\" >0.726891</td>\n      <td id=\"T_91a3b_row6_col11\" class=\"data row6 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row6_col12\" class=\"data row6 col12\" >0.913043</td>\n      <td id=\"T_91a3b_row6_col13\" class=\"data row6 col13\" >0.999978</td>\n      <td id=\"T_91a3b_row6_col14\" class=\"data row6 col14\" >0.999987</td>\n      <td id=\"T_91a3b_row6_col15\" class=\"data row6 col15\" >0.744692</td>\n      <td id=\"T_91a3b_row6_col16\" class=\"data row6 col16\" >0.959605</td>\n      <td id=\"T_91a3b_row6_col17\" class=\"data row6 col17\" >0.974786</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row7\" class=\"row_heading level0 row7\" >KNN with BO</th>\n      <td id=\"T_91a3b_row7_col0\" class=\"data row7 col0\" >0.997361</td>\n      <td id=\"T_91a3b_row7_col1\" class=\"data row7 col1\" >0.963222</td>\n      <td id=\"T_91a3b_row7_col2\" class=\"data row7 col2\" >0.823810</td>\n      <td id=\"T_91a3b_row7_col3\" class=\"data row7 col3\" >0.992442</td>\n      <td id=\"T_91a3b_row7_col4\" class=\"data row7 col4\" >0.915923</td>\n      <td id=\"T_91a3b_row7_col5\" class=\"data row7 col5\" >0.884524</td>\n      <td id=\"T_91a3b_row7_col6\" class=\"data row7 col6\" >0.897644</td>\n      <td id=\"T_91a3b_row7_col7\" class=\"data row7 col7\" >0.883117</td>\n      <td id=\"T_91a3b_row7_col8\" class=\"data row7 col8\" >0.996773</td>\n      <td id=\"T_91a3b_row7_col9\" class=\"data row7 col9\" >0.947167</td>\n      <td id=\"T_91a3b_row7_col10\" class=\"data row7 col10\" >0.704482</td>\n      <td id=\"T_91a3b_row7_col11\" class=\"data row7 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row7_col12\" class=\"data row7 col12\" >0.921459</td>\n      <td id=\"T_91a3b_row7_col13\" class=\"data row7 col13\" >0.999982</td>\n      <td id=\"T_91a3b_row7_col14\" class=\"data row7 col14\" >0.999994</td>\n      <td id=\"T_91a3b_row7_col15\" class=\"data row7 col15\" >0.753503</td>\n      <td id=\"T_91a3b_row7_col16\" class=\"data row7 col16\" >0.970745</td>\n      <td id=\"T_91a3b_row7_col17\" class=\"data row7 col17\" >0.972752</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row8\" class=\"row_heading level0 row8\" >XGB with BO</th>\n      <td id=\"T_91a3b_row8_col0\" class=\"data row8 col0\" >0.998361</td>\n      <td id=\"T_91a3b_row8_col1\" class=\"data row8 col1\" >0.963056</td>\n      <td id=\"T_91a3b_row8_col2\" class=\"data row8 col2\" >0.827143</td>\n      <td id=\"T_91a3b_row8_col3\" class=\"data row8 col3\" >0.992011</td>\n      <td id=\"T_91a3b_row8_col4\" class=\"data row8 col4\" >0.927123</td>\n      <td id=\"T_91a3b_row8_col5\" class=\"data row8 col5\" >0.998810</td>\n      <td id=\"T_91a3b_row8_col6\" class=\"data row8 col6\" >0.988906</td>\n      <td id=\"T_91a3b_row8_col7\" class=\"data row8 col7\" >0.831169</td>\n      <td id=\"T_91a3b_row8_col8\" class=\"data row8 col8\" >0.996701</td>\n      <td id=\"T_91a3b_row8_col9\" class=\"data row8 col9\" >0.953686</td>\n      <td id=\"T_91a3b_row8_col10\" class=\"data row8 col10\" >0.679272</td>\n      <td id=\"T_91a3b_row8_col11\" class=\"data row8 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row8_col12\" class=\"data row8 col12\" >0.924264</td>\n      <td id=\"T_91a3b_row8_col13\" class=\"data row8 col13\" >0.999956</td>\n      <td id=\"T_91a3b_row8_col14\" class=\"data row8 col14\" >0.999998</td>\n      <td id=\"T_91a3b_row8_col15\" class=\"data row8 col15\" >0.734489</td>\n      <td id=\"T_91a3b_row8_col16\" class=\"data row8 col16\" >0.967121</td>\n      <td id=\"T_91a3b_row8_col17\" class=\"data row8 col17\" >0.974193</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row9\" class=\"row_heading level0 row9\" >Taskwise with XGB</th>\n      <td id=\"T_91a3b_row9_col0\" class=\"data row9 col0\" >0.996056</td>\n      <td id=\"T_91a3b_row9_col1\" class=\"data row9 col1\" >0.972333</td>\n      <td id=\"T_91a3b_row9_col2\" class=\"data row9 col2\" >0.832857</td>\n      <td id=\"T_91a3b_row9_col3\" class=\"data row9 col3\" >0.990032</td>\n      <td id=\"T_91a3b_row9_col4\" class=\"data row9 col4\" >0.921863</td>\n      <td id=\"T_91a3b_row9_col5\" class=\"data row9 col5\" >1.000000</td>\n      <td id=\"T_91a3b_row9_col6\" class=\"data row9 col6\" >0.923632</td>\n      <td id=\"T_91a3b_row9_col7\" class=\"data row9 col7\" >0.861472</td>\n      <td id=\"T_91a3b_row9_col8\" class=\"data row9 col8\" >0.997273</td>\n      <td id=\"T_91a3b_row9_col9\" class=\"data row9 col9\" >0.962610</td>\n      <td id=\"T_91a3b_row9_col10\" class=\"data row9 col10\" >0.742297</td>\n      <td id=\"T_91a3b_row9_col11\" class=\"data row9 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row9_col12\" class=\"data row9 col12\" >0.934081</td>\n      <td id=\"T_91a3b_row9_col13\" class=\"data row9 col13\" >0.999879</td>\n      <td id=\"T_91a3b_row9_col14\" class=\"data row9 col14\" >0.999991</td>\n      <td id=\"T_91a3b_row9_col15\" class=\"data row9 col15\" >0.718966</td>\n      <td id=\"T_91a3b_row9_col16\" class=\"data row9 col16\" >0.958449</td>\n      <td id=\"T_91a3b_row9_col17\" class=\"data row9 col17\" >0.946038</td>\n    </tr>\n    <tr>\n      <th id=\"T_91a3b_level0_row10\" class=\"row_heading level0 row10\" >Joint with XGB</th>\n      <td id=\"T_91a3b_row10_col0\" class=\"data row10 col0\" >0.994500</td>\n      <td id=\"T_91a3b_row10_col1\" class=\"data row10 col1\" >0.968833</td>\n      <td id=\"T_91a3b_row10_col2\" class=\"data row10 col2\" >0.810000</td>\n      <td id=\"T_91a3b_row10_col3\" class=\"data row10 col3\" >0.989734</td>\n      <td id=\"T_91a3b_row10_col4\" class=\"data row10 col4\" >0.887997</td>\n      <td id=\"T_91a3b_row10_col5\" class=\"data row10 col5\" >0.500000</td>\n      <td id=\"T_91a3b_row10_col6\" class=\"data row10 col6\" >0.901596</td>\n      <td id=\"T_91a3b_row10_col7\" class=\"data row10 col7\" >0.898268</td>\n      <td id=\"T_91a3b_row10_col8\" class=\"data row10 col8\" >0.991830</td>\n      <td id=\"T_91a3b_row10_col9\" class=\"data row10 col9\" >0.953802</td>\n      <td id=\"T_91a3b_row10_col10\" class=\"data row10 col10\" >0.696078</td>\n      <td id=\"T_91a3b_row10_col11\" class=\"data row10 col11\" >0.999297</td>\n      <td id=\"T_91a3b_row10_col12\" class=\"data row10 col12\" >0.884993</td>\n      <td id=\"T_91a3b_row10_col13\" class=\"data row10 col13\" >0.999898</td>\n      <td id=\"T_91a3b_row10_col14\" class=\"data row10 col14\" >0.999990</td>\n      <td id=\"T_91a3b_row10_col15\" class=\"data row10 col15\" >0.752603</td>\n      <td id=\"T_91a3b_row10_col16\" class=\"data row10 col16\" >0.965734</td>\n      <td id=\"T_91a3b_row10_col17\" class=\"data row10 col17\" >0.976392</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Comparison of Baseline and all methods w.r.t AUC achieved with their recommended HPCs\n",
    "\"\"\"\n",
    "\n",
    "summary_df = baseline[['task_id','auc']]\n",
    "target_columns = ['task_id','new_auc']\n",
    "summary_df = pd.merge(summary_df,gb_results_default[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'auc':'baseline','new_auc':'GB default'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,rf_results_default[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'RF default'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,ffn_results_default[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'FFN default'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,mlperceptron_results_default[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'MLP default'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,knn_results_default[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'KNN default'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,rf_results_bayes[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'RF with BO'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,knn_results_bayes[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'KNN with BO'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,xgboost_results_bayes[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'XGB with BO'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,xgboost_results_taskwise_regression[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'Taskwise with XGB'}, inplace=True)\n",
    "summary_df = pd.merge(summary_df,xgboost_results_joint_regression[target_columns] , on=\"task_id\")\n",
    "summary_df.rename(columns={'new_auc':'Joint with XGB'}, inplace=True)\n",
    "summary_df['task_id'] = summary_df['task_id'].astype(int)\n",
    "summary_df = summary_df.set_index(['task_id']).transpose()\n",
    "summary_df\n",
    "summary_df.style.highlight_max(color = 'lightgreen', axis = 0).highlight_min(color = 'orange', axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times each method was as good or better than the default config\n"
     ]
    },
    {
     "data": {
      "text/plain": "GB default            9\nRF default           10\nFFN default           2\nMLP default           2\nKNN default          12\nRF with BO           10\nKNN with BO          11\nXGB with BO          13\nTaskwise with XGB     9\nJoint with XGB        7\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Count of tasks that were matched or improved upon by each method\n",
    "\"\"\"\n",
    "def improvement(row, a):\n",
    "    return row[row>=a].count()\n",
    "baseline = summary_df.loc['baseline']\n",
    "improvements = summary_df.apply(lambda x : improvement(x,baseline),axis=1)\n",
    "improvements = improvements.drop(['baseline'])\n",
    "print(\"Number of times each method was as good or better than the default config\")\n",
    "display(improvements)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of metafeatures of training tasks\n"
     ]
    },
    {
     "data": {
      "text/plain": "       MajorityClassSize  MaxNominalAttDistinctValues  MinorityClassSize  \\\ncount          94.000000                    92.000000          94.000000   \nmean         7694.946809                   267.467391        2947.297872   \nstd         15914.193136                  1779.671006        8029.261365   \nmin            16.000000                     2.000000           5.000000   \n25%           399.250000                     2.000000         178.000000   \n50%          1634.000000                     5.000000         458.500000   \n75%          4271.750000                    10.000000        1678.500000   \nmax         93565.000000                 15415.000000       47662.000000   \n\n       NumberOfClasses  NumberOfFeatures  NumberOfInstances  \\\ncount        94.000000         94.000000          94.000000   \nmean          7.808511        488.819149       16001.329787   \nstd          15.722921       1599.802393       27931.084418   \nmin           2.000000          5.000000         100.000000   \n25%           2.000000         17.000000        1252.000000   \n50%           2.000000         37.500000        3473.500000   \n75%           7.750000        120.500000       10965.250000   \nmax         100.000000      10001.000000      130064.000000   \n\n       NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\ncount                           94.000000           9.400000e+01   \nmean                           733.797872           8.578104e+04   \nstd                           5223.495247           8.275872e+05   \nmin                              0.000000           0.000000e+00   \n25%                              0.000000           0.000000e+00   \n50%                              0.000000           0.000000e+00   \n75%                              0.000000           0.000000e+00   \nmax                          50000.000000           8.024152e+06   \n\n       NumberOfNumericFeatures  NumberOfSymbolicFeatures  \ncount                94.000000                 94.000000  \nmean                478.627660                 10.191489  \nstd                1601.857732                 25.847059  \nmin                   0.000000                  1.000000  \n25%                   7.000000                  1.000000  \n50%                  27.000000                  1.000000  \n75%                  86.000000                  5.750000  \nmax               10000.000000                181.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MajorityClassSize</th>\n      <th>MaxNominalAttDistinctValues</th>\n      <th>MinorityClassSize</th>\n      <th>NumberOfClasses</th>\n      <th>NumberOfFeatures</th>\n      <th>NumberOfInstances</th>\n      <th>NumberOfInstancesWithMissingValues</th>\n      <th>NumberOfMissingValues</th>\n      <th>NumberOfNumericFeatures</th>\n      <th>NumberOfSymbolicFeatures</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>94.000000</td>\n      <td>92.000000</td>\n      <td>94.000000</td>\n      <td>94.000000</td>\n      <td>94.000000</td>\n      <td>94.000000</td>\n      <td>94.000000</td>\n      <td>9.400000e+01</td>\n      <td>94.000000</td>\n      <td>94.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7694.946809</td>\n      <td>267.467391</td>\n      <td>2947.297872</td>\n      <td>7.808511</td>\n      <td>488.819149</td>\n      <td>16001.329787</td>\n      <td>733.797872</td>\n      <td>8.578104e+04</td>\n      <td>478.627660</td>\n      <td>10.191489</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>15914.193136</td>\n      <td>1779.671006</td>\n      <td>8029.261365</td>\n      <td>15.722921</td>\n      <td>1599.802393</td>\n      <td>27931.084418</td>\n      <td>5223.495247</td>\n      <td>8.275872e+05</td>\n      <td>1601.857732</td>\n      <td>25.847059</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>16.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>399.250000</td>\n      <td>2.000000</td>\n      <td>178.000000</td>\n      <td>2.000000</td>\n      <td>17.000000</td>\n      <td>1252.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1634.000000</td>\n      <td>5.000000</td>\n      <td>458.500000</td>\n      <td>2.000000</td>\n      <td>37.500000</td>\n      <td>3473.500000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>27.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4271.750000</td>\n      <td>10.000000</td>\n      <td>1678.500000</td>\n      <td>7.750000</td>\n      <td>120.500000</td>\n      <td>10965.250000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>86.000000</td>\n      <td>5.750000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>93565.000000</td>\n      <td>15415.000000</td>\n      <td>47662.000000</td>\n      <td>100.000000</td>\n      <td>10001.000000</td>\n      <td>130064.000000</td>\n      <td>50000.000000</td>\n      <td>8.024152e+06</td>\n      <td>10000.000000</td>\n      <td>181.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Checking if there are any differences in metafeatures on tasks 22,31,3913 compared to the others - No clear differences\n",
    "\"\"\"\n",
    "print(\"Summary of metafeatures of training tasks\")\n",
    "meta_train[training_meta_features].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of metafeatures for tasks that were not improved\n"
     ]
    },
    {
     "data": {
      "text/plain": "       MajorityClassSize  MaxNominalAttDistinctValues  MinorityClassSize  \\\ncount           3.000000                     3.000000           3.000000   \nmean          438.333333                     7.333333         202.333333   \nstd           250.815337                     4.618802          96.521155   \nmin           200.000000                     2.000000         107.000000   \n25%           307.500000                     6.000000         153.500000   \n50%           415.000000                    10.000000         200.000000   \n75%           557.500000                    10.000000         250.000000   \nmax           700.000000                    10.000000         300.000000   \n\n       NumberOfClasses  NumberOfFeatures  NumberOfInstances  \\\ncount         3.000000          3.000000           3.000000   \nmean          4.666667         30.333333        1174.000000   \nstd           4.618802         15.307950         754.206868   \nmin           2.000000         21.000000         522.000000   \n25%           2.000000         21.500000         761.000000   \n50%           2.000000         22.000000        1000.000000   \n75%           6.000000         35.000000        1500.000000   \nmax          10.000000         48.000000        2000.000000   \n\n       NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\ncount                                 3.0                    3.0   \nmean                                  0.0                    0.0   \nstd                                   0.0                    0.0   \nmin                                   0.0                    0.0   \n25%                                   0.0                    0.0   \n50%                                   0.0                    0.0   \n75%                                   0.0                    0.0   \nmax                                   0.0                    0.0   \n\n       NumberOfNumericFeatures  NumberOfSymbolicFeatures  \ncount                 3.000000                  3.000000  \nmean                 25.000000                  5.333333  \nstd                  20.297783                  7.505553  \nmin                   7.000000                  1.000000  \n25%                  14.000000                  1.000000  \n50%                  21.000000                  1.000000  \n75%                  34.000000                  7.500000  \nmax                  47.000000                 14.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MajorityClassSize</th>\n      <th>MaxNominalAttDistinctValues</th>\n      <th>MinorityClassSize</th>\n      <th>NumberOfClasses</th>\n      <th>NumberOfFeatures</th>\n      <th>NumberOfInstances</th>\n      <th>NumberOfInstancesWithMissingValues</th>\n      <th>NumberOfMissingValues</th>\n      <th>NumberOfNumericFeatures</th>\n      <th>NumberOfSymbolicFeatures</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>438.333333</td>\n      <td>7.333333</td>\n      <td>202.333333</td>\n      <td>4.666667</td>\n      <td>30.333333</td>\n      <td>1174.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.000000</td>\n      <td>5.333333</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>250.815337</td>\n      <td>4.618802</td>\n      <td>96.521155</td>\n      <td>4.618802</td>\n      <td>15.307950</td>\n      <td>754.206868</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.297783</td>\n      <td>7.505553</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>200.000000</td>\n      <td>2.000000</td>\n      <td>107.000000</td>\n      <td>2.000000</td>\n      <td>21.000000</td>\n      <td>522.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>307.500000</td>\n      <td>6.000000</td>\n      <td>153.500000</td>\n      <td>2.000000</td>\n      <td>21.500000</td>\n      <td>761.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>415.000000</td>\n      <td>10.000000</td>\n      <td>200.000000</td>\n      <td>2.000000</td>\n      <td>22.000000</td>\n      <td>1000.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>557.500000</td>\n      <td>10.000000</td>\n      <td>250.000000</td>\n      <td>6.000000</td>\n      <td>35.000000</td>\n      <td>1500.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>34.000000</td>\n      <td>7.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>700.000000</td>\n      <td>10.000000</td>\n      <td>300.000000</td>\n      <td>10.000000</td>\n      <td>48.000000</td>\n      <td>2000.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>47.000000</td>\n      <td>14.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_improved = [22,31,3913]\n",
    "meta_not_improved = meta_test[meta_test['task_id'].isin(not_improved)][training_meta_features]\n",
    "meta_improved = meta_test[~meta_test['task_id'].isin(not_improved)][training_meta_features]\n",
    "print(\"Summary of metafeatures for tasks that were not improved\")\n",
    "meta_not_improved.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of metafeatures for tasks that were improved\n"
     ]
    },
    {
     "data": {
      "text/plain": "       MajorityClassSize  MaxNominalAttDistinctValues  MinorityClassSize  \\\ncount          15.000000                    14.000000           15.00000   \nmean        11198.666667                    11.714286         1227.00000   \nstd         19170.843184                    18.635898         2420.89287   \nmin            60.000000                     2.000000           10.00000   \n25%           353.500000                     2.000000           86.50000   \n50%          1944.000000                     5.000000          206.00000   \n75%         11807.500000                     9.250000         1015.50000   \nmax         64007.000000                    71.000000         8976.00000   \n\n       NumberOfClasses  NumberOfFeatures  NumberOfInstances  \\\ncount        15.000000         15.000000          15.000000   \nmean          4.866667        248.533333       15330.066667   \nstd           4.867775        501.705216       23390.641338   \nmin           2.000000          6.000000         540.000000   \n25%           2.000000         10.500000         668.500000   \n50%           2.000000         33.000000        5404.000000   \n75%           6.000000         52.500000       12269.500000   \nmax          20.000000       1559.000000       72983.000000   \n\n       NumberOfInstancesWithMissingValues  NumberOfMissingValues  \\\ncount                           15.000000              15.000000   \nmean                          4671.133333           10047.866667   \nstd                          17992.320933           38515.892618   \nmin                              0.000000               0.000000   \n25%                              0.000000               0.000000   \n50%                              0.000000               0.000000   \n75%                              0.000000               0.000000   \nmax                          69709.000000          149271.000000   \n\n       NumberOfNumericFeatures  NumberOfSymbolicFeatures  \ncount                15.000000                 15.000000  \nmean                140.466667                108.066667  \nstd                 350.249068                400.615859  \nmin                   0.000000                  1.000000  \n25%                   7.500000                  1.000000  \n50%                  14.000000                  1.000000  \n75%                  37.000000                  6.500000  \nmax                1300.000000               1556.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MajorityClassSize</th>\n      <th>MaxNominalAttDistinctValues</th>\n      <th>MinorityClassSize</th>\n      <th>NumberOfClasses</th>\n      <th>NumberOfFeatures</th>\n      <th>NumberOfInstances</th>\n      <th>NumberOfInstancesWithMissingValues</th>\n      <th>NumberOfMissingValues</th>\n      <th>NumberOfNumericFeatures</th>\n      <th>NumberOfSymbolicFeatures</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>15.000000</td>\n      <td>14.000000</td>\n      <td>15.00000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>11198.666667</td>\n      <td>11.714286</td>\n      <td>1227.00000</td>\n      <td>4.866667</td>\n      <td>248.533333</td>\n      <td>15330.066667</td>\n      <td>4671.133333</td>\n      <td>10047.866667</td>\n      <td>140.466667</td>\n      <td>108.066667</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>19170.843184</td>\n      <td>18.635898</td>\n      <td>2420.89287</td>\n      <td>4.867775</td>\n      <td>501.705216</td>\n      <td>23390.641338</td>\n      <td>17992.320933</td>\n      <td>38515.892618</td>\n      <td>350.249068</td>\n      <td>400.615859</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>60.000000</td>\n      <td>2.000000</td>\n      <td>10.00000</td>\n      <td>2.000000</td>\n      <td>6.000000</td>\n      <td>540.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>353.500000</td>\n      <td>2.000000</td>\n      <td>86.50000</td>\n      <td>2.000000</td>\n      <td>10.500000</td>\n      <td>668.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.500000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1944.000000</td>\n      <td>5.000000</td>\n      <td>206.00000</td>\n      <td>2.000000</td>\n      <td>33.000000</td>\n      <td>5404.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>11807.500000</td>\n      <td>9.250000</td>\n      <td>1015.50000</td>\n      <td>6.000000</td>\n      <td>52.500000</td>\n      <td>12269.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>37.000000</td>\n      <td>6.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>64007.000000</td>\n      <td>71.000000</td>\n      <td>8976.00000</td>\n      <td>20.000000</td>\n      <td>1559.000000</td>\n      <td>72983.000000</td>\n      <td>69709.000000</td>\n      <td>149271.000000</td>\n      <td>1300.000000</td>\n      <td>1556.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Summary of metafeatures for tasks that were improved\")\n",
    "meta_improved.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                               feature  importance             type\n14                               alpha    0.171885  hyper_parameter\n5                    NumberOfInstances    0.157089             meta\n17                    min_child_weight    0.088594  hyper_parameter\n2                    MinorityClassSize    0.066281             meta\n1          MaxNominalAttDistinctValues    0.064346             meta\n6   NumberOfInstancesWithMissingValues    0.055369             meta\n4                     NumberOfFeatures    0.051803             meta\n8              NumberOfNumericFeatures    0.050696             meta\n15                           subsample    0.042902  hyper_parameter\n3                      NumberOfClasses    0.040909             meta\n9             NumberOfSymbolicFeatures    0.040573             meta\n0                    MajorityClassSize    0.038191             meta\n12                               gamma    0.032006  hyper_parameter\n13                              lambda    0.023375  hyper_parameter\n7                NumberOfMissingValues    0.022341             meta\n10                           num_round    0.012599  hyper_parameter\n18                    colsample_bytree    0.011695  hyper_parameter\n19                   colsample_bylevel    0.010949  hyper_parameter\n11                                 eta    0.009229  hyper_parameter\n16                           max_depth    0.009166  hyper_parameter",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>alpha</td>\n      <td>0.171885</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NumberOfInstances</td>\n      <td>0.157089</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>min_child_weight</td>\n      <td>0.088594</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MinorityClassSize</td>\n      <td>0.066281</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MaxNominalAttDistinctValues</td>\n      <td>0.064346</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NumberOfInstancesWithMissingValues</td>\n      <td>0.055369</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NumberOfFeatures</td>\n      <td>0.051803</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NumberOfNumericFeatures</td>\n      <td>0.050696</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>subsample</td>\n      <td>0.042902</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NumberOfClasses</td>\n      <td>0.040909</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NumberOfSymbolicFeatures</td>\n      <td>0.040573</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>MajorityClassSize</td>\n      <td>0.038191</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>gamma</td>\n      <td>0.032006</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>lambda</td>\n      <td>0.023375</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NumberOfMissingValues</td>\n      <td>0.022341</td>\n      <td>meta</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>num_round</td>\n      <td>0.012599</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>colsample_bytree</td>\n      <td>0.011695</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>colsample_bylevel</td>\n      <td>0.010949</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>eta</td>\n      <td>0.009229</td>\n      <td>hyper_parameter</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max_depth</td>\n      <td>0.009166</td>\n      <td>hyper_parameter</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Loading results of Joint data regression - This will take around a minute\n",
    "\"\"\"\n",
    "def bayes_callback(res):\n",
    "    print(\"Next iteration, Time:\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "with open('full_data_xgboost_search.pkl', 'rb') as f:\n",
    "    joint_regression_searches = pickle.load(f)\n",
    "with open('full_data_xgboost_result.pkl', 'rb') as f:\n",
    "    scores = pickle.load(f)\n",
    "joint_regression_searches\n",
    "#Getting the regression model that had the best CV score on nested sampling\n",
    "best_regressor = joint_regression_searches[np.argmax(scores)].best_estimator_\n",
    "best_search_results = joint_regression_searches[np.argmax(scores)].cv_results_\n",
    "\"\"\"\n",
    "    Here we can see the importance of different dataset metafeatures as well as XGBoost hyperparameters\n",
    "    for determining the AUC. We use the regressor from the Joint regression approach that had the best\n",
    "    score in nested sampling.\n",
    "\"\"\"\n",
    "train_features = training_meta_features + hyperparameters_data\n",
    "feature_importance = pd.DataFrame({'feature': train_features, 'importance': list(best_regressor.feature_importances_)}, columns=['feature', 'importance'])\n",
    "feature_importance['type'] = len(training_meta_features)*['meta'] + len(hyperparameters_data)*['hyper_parameter']\n",
    "feature_importance.sort_values(by=['importance'],ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This is an example of how to use BayesSearchCV cv_results_\n",
    "    For each of the inner folds (5 in total) we have the cost metric\n",
    "\"\"\"\n",
    "splits  = []\n",
    "splits.append(best_search_results['split0_test_score'])\n",
    "splits.append(best_search_results['split1_test_score'])\n",
    "splits.append(best_search_results['split2_test_score'])\n",
    "splits.append(best_search_results['split3_test_score'])\n",
    "splits.append(best_search_results['split4_test_score'])\n",
    "\n",
    "\"\"\"\n",
    "    Example - plotting scores for each split - Unclear why some of the BayesSearchCV scores are negative since it should be using RMSE from XGBRegressor\n",
    "\"\"\"\n",
    "for split in splits:\n",
    "    best_in_split = [split[0]]\n",
    "    for score in split[1:]:\n",
    "        best_in_split.append(min(score,best_in_split[len(best_in_split)-1]))\n",
    "    plt.step(range(1,len(split)+1),best_in_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n    The following cells give examples of how to run different methods from the Project Report\\n'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    The following cells give examples of how to run different methods from the Project Report\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random forest regressor \n",
      "\n",
      "Evaluating task with id:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9984166666666667\n",
      "Evaluating task with id:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9695277777777778\n",
      "Evaluating task with id:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8261904761904761\n",
      "Evaluating task with id:  2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9920507347036649\n",
      "Evaluating task with id:  2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9174908364824852\n",
      "Evaluating task with id:  3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.838095238095238\n",
      "Evaluating task with id:  3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9120820668693008\n",
      "Evaluating task with id:  3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8852813852813852\n",
      "Evaluating task with id:  9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.996148434898435\n",
      "Evaluating task with id:  9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9575718660476144\n",
      "Evaluating task with id:  9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7030812324929971\n",
      "Evaluating task with id:  10106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.99929676511955\n",
      "Evaluating task with id:  14954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9102384291725105\n",
      "Evaluating task with id:  14970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9999795198830181\n",
      "Evaluating task with id:  146212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9999823101260665\n",
      "Evaluating task with id:  167119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9749303479773376\n",
      "Evaluating task with id:  167125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9534767190872648\n",
      "Evaluating task with id:  168336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7468884490139174\n"
     ]
    },
    {
     "data": {
      "text/plain": "    task_id  base_auc   base_time   new_auc    new_time     delta_auc  \\\n0        16  0.997222   31.225133  0.998417   10.395434  1.194444e-03   \n1        22  0.973361   25.774230  0.969528    9.640014 -3.833333e-03   \n2        31  0.841905    1.274992  0.826190    0.426011 -1.571429e-02   \n3      2074  0.989416   18.240999  0.992051   17.952959  2.634807e-03   \n4      2079  0.915436    3.369999  0.917491    5.100997  2.054996e-03   \n5      3493  0.976190    0.539915  0.838095    0.224997 -1.380952e-01   \n6      3907  0.985866    2.770957  0.912082    1.841963 -7.378419e-02   \n7      3913  0.906926    0.559001  0.885281    0.394960 -2.164502e-02   \n8      9950  0.996221   32.786961  0.996148   30.764871 -7.217320e-05   \n9      9952  0.956024    2.991995  0.957572    1.981998  1.547631e-03   \n10     9971  0.668067    0.624963  0.703081    0.269957  3.501401e-02   \n11    10106  0.999297    9.776999  0.999297    3.894962  0.000000e+00   \n12    14954  0.910238    0.831042  0.910238    1.610968  1.110223e-16   \n13    14970  0.999844  748.155138  0.999980   76.179997  1.358786e-04   \n14   146212  0.999998   30.165969  0.999982   43.123998 -1.611051e-05   \n15   167119  0.969022   34.102057  0.974930   37.524650  5.908409e-03   \n16   167125  0.962805   64.667999  0.953477   24.528991 -9.327783e-03   \n17   168336  0.735831  170.242889  0.746888  149.412001  1.105705e-02   \n\n    better_auc  better_time  \n0         True         True  \n1        False         True  \n2        False         True  \n3         True         True  \n4         True        False  \n5        False         True  \n6        False         True  \n7        False         True  \n8        False         True  \n9         True         True  \n10        True         True  \n11       False         True  \n12        True        False  \n13        True         True  \n14       False        False  \n15        True        False  \n16       False         True  \n17        True         True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>base_auc</th>\n      <th>base_time</th>\n      <th>new_auc</th>\n      <th>new_time</th>\n      <th>delta_auc</th>\n      <th>better_auc</th>\n      <th>better_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>0.997222</td>\n      <td>31.225133</td>\n      <td>0.998417</td>\n      <td>10.395434</td>\n      <td>1.194444e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>0.973361</td>\n      <td>25.774230</td>\n      <td>0.969528</td>\n      <td>9.640014</td>\n      <td>-3.833333e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>0.841905</td>\n      <td>1.274992</td>\n      <td>0.826190</td>\n      <td>0.426011</td>\n      <td>-1.571429e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2074</td>\n      <td>0.989416</td>\n      <td>18.240999</td>\n      <td>0.992051</td>\n      <td>17.952959</td>\n      <td>2.634807e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2079</td>\n      <td>0.915436</td>\n      <td>3.369999</td>\n      <td>0.917491</td>\n      <td>5.100997</td>\n      <td>2.054996e-03</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3493</td>\n      <td>0.976190</td>\n      <td>0.539915</td>\n      <td>0.838095</td>\n      <td>0.224997</td>\n      <td>-1.380952e-01</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3907</td>\n      <td>0.985866</td>\n      <td>2.770957</td>\n      <td>0.912082</td>\n      <td>1.841963</td>\n      <td>-7.378419e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3913</td>\n      <td>0.906926</td>\n      <td>0.559001</td>\n      <td>0.885281</td>\n      <td>0.394960</td>\n      <td>-2.164502e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9950</td>\n      <td>0.996221</td>\n      <td>32.786961</td>\n      <td>0.996148</td>\n      <td>30.764871</td>\n      <td>-7.217320e-05</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9952</td>\n      <td>0.956024</td>\n      <td>2.991995</td>\n      <td>0.957572</td>\n      <td>1.981998</td>\n      <td>1.547631e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9971</td>\n      <td>0.668067</td>\n      <td>0.624963</td>\n      <td>0.703081</td>\n      <td>0.269957</td>\n      <td>3.501401e-02</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10106</td>\n      <td>0.999297</td>\n      <td>9.776999</td>\n      <td>0.999297</td>\n      <td>3.894962</td>\n      <td>0.000000e+00</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14954</td>\n      <td>0.910238</td>\n      <td>0.831042</td>\n      <td>0.910238</td>\n      <td>1.610968</td>\n      <td>1.110223e-16</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14970</td>\n      <td>0.999844</td>\n      <td>748.155138</td>\n      <td>0.999980</td>\n      <td>76.179997</td>\n      <td>1.358786e-04</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>146212</td>\n      <td>0.999998</td>\n      <td>30.165969</td>\n      <td>0.999982</td>\n      <td>43.123998</td>\n      <td>-1.611051e-05</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>167119</td>\n      <td>0.969022</td>\n      <td>34.102057</td>\n      <td>0.974930</td>\n      <td>37.524650</td>\n      <td>5.908409e-03</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>167125</td>\n      <td>0.962805</td>\n      <td>64.667999</td>\n      <td>0.953477</td>\n      <td>24.528991</td>\n      <td>-9.327783e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>168336</td>\n      <td>0.735831</td>\n      <td>170.242889</td>\n      <td>0.746888</td>\n      <td>149.412001</td>\n      <td>1.105705e-02</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    1.Direct regression with single regressor for all 10 hyperparameters - no HPO\n",
    "    This should take 5-10min.\n",
    "\"\"\"\n",
    "print(\"Fitting Random forest regressor \\n\")\n",
    "random_forest_results = compare_regressor_with_baseline(regressor=ensemble.RandomForestRegressor())\n",
    "display(random_forest_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting bayesian optimisation of regressors \n",
      " Time = 16:38:21\n",
      "{'num_round': {'best score': -0.8793371215508963, 'best config': OrderedDict([('bootstrap', 'True'), ('max_depth', 21), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 10), ('n_estimators', 329)])}, 'eta': {'best score': -0.5838586920218367, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 8), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 10), ('n_estimators', 52)])}, 'gamma': {'best score': -131.41977413809772, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 23), ('max_features', 'sqrt'), ('min_samples_leaf', 2), ('min_samples_split', 5), ('n_estimators', 381)])}, 'lambda': {'best score': -37.244871905779156, 'best config': OrderedDict([('bootstrap', 'True'), ('max_depth', 19), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 5), ('n_estimators', 391)])}, 'alpha': {'best score': -106.41896754222762, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 16), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 5), ('n_estimators', 70)])}, 'subsample': {'best score': -0.3380128508776362, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 19), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 5), ('n_estimators', 176)])}, 'max_depth': {'best score': -0.2930889048228998, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 9), ('max_features', 'sqrt'), ('min_samples_leaf', 2), ('min_samples_split', 10), ('n_estimators', 451)])}, 'min_child_weight': {'best score': -5.475822327806219, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 8), ('max_features', 'sqrt'), ('min_samples_leaf', 2), ('min_samples_split', 10), ('n_estimators', 60)])}, 'colsample_bytree': {'best score': -0.07878233794911989, 'best config': OrderedDict([('bootstrap', 'False'), ('max_depth', 19), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 5), ('n_estimators', 457)])}, 'colsample_bylevel': {'best score': -0.36827866735247156, 'best config': OrderedDict([('bootstrap', 'True'), ('max_depth', 15), ('max_features', 'sqrt'), ('min_samples_leaf', 4), ('min_samples_split', 10), ('n_estimators', 255)])}}\n",
      "Evaluating task with id:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.99825\n",
      "Evaluating task with id:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9663333333333333\n",
      "Evaluating task with id:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8204761904761904\n",
      "Evaluating task with id:  2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9914490637757601\n",
      "Evaluating task with id:  2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9223247479742994\n",
      "Evaluating task with id:  3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8999999999999999\n",
      "Evaluating task with id:  3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9213525835866262\n",
      "Evaluating task with id:  3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8961038961038961\n",
      "Evaluating task with id:  9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9928089673484412\n",
      "Evaluating task with id:  9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9564852316506965\n",
      "Evaluating task with id:  9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.6918767507002801\n",
      "Evaluating task with id:  10106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9992967651195499\n",
      "Evaluating task with id:  14954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9186535764375876\n",
      "Evaluating task with id:  14970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.999982141591469\n",
      "Evaluating task with id:  146212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9999896009486854\n",
      "Evaluating task with id:  167119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9731176585328724\n",
      "Evaluating task with id:  167125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9639993832870799\n",
      "Evaluating task with id:  168336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7481594781439008\n"
     ]
    },
    {
     "data": {
      "text/plain": "    task_id  base_auc   base_time   new_auc    new_time     delta_auc  \\\n0        16  0.997222   31.225133  0.998250   12.757062  1.027778e-03   \n1        22  0.973361   25.774230  0.966333   12.422971 -7.027778e-03   \n2        31  0.841905    1.274992  0.820476    0.727962 -2.142857e-02   \n3      2074  0.989416   18.240999  0.991449   15.412041  2.033136e-03   \n4      2079  0.915436    3.369999  0.922325    2.988997  6.888907e-03   \n5      3493  0.976190    0.539915  0.900000    0.473002 -7.619048e-02   \n6      3907  0.985866    2.770957  0.921353    2.203002 -6.451368e-02   \n7      3913  0.906926    0.559001  0.896104    0.507999 -1.082251e-02   \n8      9950  0.996221   32.786961  0.992809   25.730000 -3.411641e-03   \n9      9952  0.956024    2.991995  0.956485    2.261042  4.609964e-04   \n10     9971  0.668067    0.624963  0.691877    0.509959  2.380952e-02   \n11    10106  0.999297    9.776999  0.999297    3.679961 -1.110223e-16   \n12    14954  0.910238    0.831042  0.918654    1.088998  8.415147e-03   \n13    14970  0.999844  748.155138  0.999982   71.854997  1.385003e-04   \n14   146212  0.999998   30.165969  0.999990   41.709719 -8.819687e-06   \n15   167119  0.969022   34.102057  0.973118   25.926018  4.095719e-03   \n16   167125  0.962805   64.667999  0.963999   30.680671  1.194881e-03   \n17   168336  0.735831  170.242889  0.748159  135.451043  1.232808e-02   \n\n    better_auc  better_time  \n0         True         True  \n1        False         True  \n2        False         True  \n3         True         True  \n4         True         True  \n5        False         True  \n6        False         True  \n7        False         True  \n8        False         True  \n9         True         True  \n10        True         True  \n11       False         True  \n12        True        False  \n13        True         True  \n14       False        False  \n15        True         True  \n16        True         True  \n17        True         True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>base_auc</th>\n      <th>base_time</th>\n      <th>new_auc</th>\n      <th>new_time</th>\n      <th>delta_auc</th>\n      <th>better_auc</th>\n      <th>better_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>0.997222</td>\n      <td>31.225133</td>\n      <td>0.998250</td>\n      <td>12.757062</td>\n      <td>1.027778e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>0.973361</td>\n      <td>25.774230</td>\n      <td>0.966333</td>\n      <td>12.422971</td>\n      <td>-7.027778e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>0.841905</td>\n      <td>1.274992</td>\n      <td>0.820476</td>\n      <td>0.727962</td>\n      <td>-2.142857e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2074</td>\n      <td>0.989416</td>\n      <td>18.240999</td>\n      <td>0.991449</td>\n      <td>15.412041</td>\n      <td>2.033136e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2079</td>\n      <td>0.915436</td>\n      <td>3.369999</td>\n      <td>0.922325</td>\n      <td>2.988997</td>\n      <td>6.888907e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3493</td>\n      <td>0.976190</td>\n      <td>0.539915</td>\n      <td>0.900000</td>\n      <td>0.473002</td>\n      <td>-7.619048e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3907</td>\n      <td>0.985866</td>\n      <td>2.770957</td>\n      <td>0.921353</td>\n      <td>2.203002</td>\n      <td>-6.451368e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3913</td>\n      <td>0.906926</td>\n      <td>0.559001</td>\n      <td>0.896104</td>\n      <td>0.507999</td>\n      <td>-1.082251e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9950</td>\n      <td>0.996221</td>\n      <td>32.786961</td>\n      <td>0.992809</td>\n      <td>25.730000</td>\n      <td>-3.411641e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9952</td>\n      <td>0.956024</td>\n      <td>2.991995</td>\n      <td>0.956485</td>\n      <td>2.261042</td>\n      <td>4.609964e-04</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9971</td>\n      <td>0.668067</td>\n      <td>0.624963</td>\n      <td>0.691877</td>\n      <td>0.509959</td>\n      <td>2.380952e-02</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10106</td>\n      <td>0.999297</td>\n      <td>9.776999</td>\n      <td>0.999297</td>\n      <td>3.679961</td>\n      <td>-1.110223e-16</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14954</td>\n      <td>0.910238</td>\n      <td>0.831042</td>\n      <td>0.918654</td>\n      <td>1.088998</td>\n      <td>8.415147e-03</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14970</td>\n      <td>0.999844</td>\n      <td>748.155138</td>\n      <td>0.999982</td>\n      <td>71.854997</td>\n      <td>1.385003e-04</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>146212</td>\n      <td>0.999998</td>\n      <td>30.165969</td>\n      <td>0.999990</td>\n      <td>41.709719</td>\n      <td>-8.819687e-06</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>167119</td>\n      <td>0.969022</td>\n      <td>34.102057</td>\n      <td>0.973118</td>\n      <td>25.926018</td>\n      <td>4.095719e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>167125</td>\n      <td>0.962805</td>\n      <td>64.667999</td>\n      <td>0.963999</td>\n      <td>30.680671</td>\n      <td>1.194881e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>168336</td>\n      <td>0.735831</td>\n      <td>170.242889</td>\n      <td>0.748159</td>\n      <td>135.451043</td>\n      <td>1.232808e-02</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    2.Direct regression with a separate model for eahc parametr. Each model is optimised using Bayesian Optimisation\n",
    "    This should take 5-10min.\n",
    "\n",
    "    Note: If you want the model to be retrained from scratch you have to:\n",
    "        1) Remove bayes_rforest.pkl\n",
    "    Also, the number of BO iterations was lowered from 50 to 10 in order to speedup the function,\n",
    "    if you want to get the same results as seen in the table above change it n_iter to 50.\n",
    "    In that case the following function call will take around 1 hour.\n",
    "\n",
    "\"\"\"\n",
    "#Results of this run will be saved at 'bayes_rforest.pkl and bayes_rforest.csv'\n",
    "ADDRESS_TO_SAVE = 'bayes_rforest'\n",
    "search_space = dict()\n",
    "search_space['n_estimators'] = (50, 500)\n",
    "search_space['max_features'] = ['auto', 'sqrt']\n",
    "search_space['max_depth'] = (5, 25)\n",
    "search_space['min_samples_split'] = [2, 5, 10]\n",
    "search_space['min_samples_leaf'] = [1, 2, 4]\n",
    "search_space['bootstrap'] = ['True', 'False']\n",
    "\n",
    "bayes_forest_result = evaluate_bayesian_regressors(estimator=ensemble.RandomForestRegressor(),\n",
    "                                                   search_space=search_space,\n",
    "                                                   address_to_save=ADDRESS_TO_SAVE, n_iter=10)\n",
    "display(bayes_forest_result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{16: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 22: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 31: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 2074: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 2079: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 3493: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 3907: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 3913: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 9950: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 9952: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 9971: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 10106: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 14954: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 14970: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 146212: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 167119: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 167125: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}, 168336: {'num_round': 188.0, 'eta': 0.4288125398914157, 'gamma': 3.493257533344619, 'lambda': 8.206003512351286, 'alpha': 1.6462670933273371, 'subsample': 0.8982073569636021, 'max_depth': 14.0, 'min_child_weight': 4.128811685866609, 'colsample_bytree': 0.9138330878345237, 'colsample_bylevel': 0.8081015093193678}}\n",
      "Evaluating task with id:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9939722222222223\n",
      "Evaluating task with id:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9740277777777777\n",
      "Evaluating task with id:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8180952380952381\n",
      "Evaluating task with id:  2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.985902445760361\n",
      "Evaluating task with id:  2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8992249545141597\n",
      "Evaluating task with id:  3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9142857142857143\n",
      "Evaluating task with id:  3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8974924012158055\n",
      "Evaluating task with id:  3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8885281385281386\n",
      "Evaluating task with id:  9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.993205391100128\n",
      "Evaluating task with id:  9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9425565543811124\n",
      "Evaluating task with id:  9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.6988795518207283\n",
      "Evaluating task with id:  10106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9992967651195499\n",
      "Evaluating task with id:  14954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8709677419354839\n",
      "Evaluating task with id:  14970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9998302371865412\n",
      "Evaluating task with id:  146212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9999939602922845\n",
      "Evaluating task with id:  167119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9759238906819124\n",
      "Evaluating task with id:  167125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9680465618254702\n",
      "Evaluating task with id:  168336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7388805827597233\n"
     ]
    },
    {
     "data": {
      "text/plain": "    task_id  base_auc   base_time   new_auc    new_time     delta_auc  \\\n0        16  0.997222   31.225133  0.993972    7.712000 -3.250000e-03   \n1        22  0.973361   25.774230  0.974028    6.286959  6.666667e-04   \n2        31  0.841905    1.274992  0.818095    0.351998 -2.380952e-02   \n3      2074  0.989416   18.240999  0.985902    5.076998 -3.513482e-03   \n4      2079  0.915436    3.369999  0.899225    0.949959 -1.621089e-02   \n5      3493  0.976190    0.539915  0.914286    0.200958 -6.190476e-02   \n6      3907  0.985866    2.770957  0.897492    0.811960 -8.837386e-02   \n7      3913  0.906926    0.559001  0.888528    0.186999 -1.839827e-02   \n8      9950  0.996221   32.786961  0.993205   10.034963 -3.015217e-03   \n9      9952  0.956024    2.991995  0.942557    0.832959 -1.346768e-02   \n10     9971  0.668067    0.624963  0.698880    0.201958  3.081232e-02   \n11    10106  0.999297    9.776999  0.999297    1.027959 -1.110223e-16   \n12    14954  0.910238    0.831042  0.870968    0.269962 -3.927069e-02   \n13    14970  0.999844  748.155138  0.999830  166.376002 -1.340407e-05   \n14   146212  0.999998   30.165969  0.999994    9.906997 -4.460343e-06   \n15   167119  0.969022   34.102057  0.975924   11.336961  6.901951e-03   \n16   167125  0.962805   64.667999  0.968047   16.358957  5.242060e-03   \n17   168336  0.735831  170.242889  0.738881   68.541956  3.049183e-03   \n\n    better_auc  better_time  \n0        False         True  \n1         True         True  \n2        False         True  \n3        False         True  \n4        False         True  \n5        False         True  \n6        False         True  \n7        False         True  \n8        False         True  \n9        False         True  \n10        True         True  \n11       False         True  \n12       False         True  \n13       False         True  \n14       False         True  \n15        True         True  \n16        True         True  \n17        True         True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>base_auc</th>\n      <th>base_time</th>\n      <th>new_auc</th>\n      <th>new_time</th>\n      <th>delta_auc</th>\n      <th>better_auc</th>\n      <th>better_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>0.997222</td>\n      <td>31.225133</td>\n      <td>0.993972</td>\n      <td>7.712000</td>\n      <td>-3.250000e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>0.973361</td>\n      <td>25.774230</td>\n      <td>0.974028</td>\n      <td>6.286959</td>\n      <td>6.666667e-04</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>0.841905</td>\n      <td>1.274992</td>\n      <td>0.818095</td>\n      <td>0.351998</td>\n      <td>-2.380952e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2074</td>\n      <td>0.989416</td>\n      <td>18.240999</td>\n      <td>0.985902</td>\n      <td>5.076998</td>\n      <td>-3.513482e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2079</td>\n      <td>0.915436</td>\n      <td>3.369999</td>\n      <td>0.899225</td>\n      <td>0.949959</td>\n      <td>-1.621089e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3493</td>\n      <td>0.976190</td>\n      <td>0.539915</td>\n      <td>0.914286</td>\n      <td>0.200958</td>\n      <td>-6.190476e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3907</td>\n      <td>0.985866</td>\n      <td>2.770957</td>\n      <td>0.897492</td>\n      <td>0.811960</td>\n      <td>-8.837386e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3913</td>\n      <td>0.906926</td>\n      <td>0.559001</td>\n      <td>0.888528</td>\n      <td>0.186999</td>\n      <td>-1.839827e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9950</td>\n      <td>0.996221</td>\n      <td>32.786961</td>\n      <td>0.993205</td>\n      <td>10.034963</td>\n      <td>-3.015217e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9952</td>\n      <td>0.956024</td>\n      <td>2.991995</td>\n      <td>0.942557</td>\n      <td>0.832959</td>\n      <td>-1.346768e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9971</td>\n      <td>0.668067</td>\n      <td>0.624963</td>\n      <td>0.698880</td>\n      <td>0.201958</td>\n      <td>3.081232e-02</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10106</td>\n      <td>0.999297</td>\n      <td>9.776999</td>\n      <td>0.999297</td>\n      <td>1.027959</td>\n      <td>-1.110223e-16</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14954</td>\n      <td>0.910238</td>\n      <td>0.831042</td>\n      <td>0.870968</td>\n      <td>0.269962</td>\n      <td>-3.927069e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14970</td>\n      <td>0.999844</td>\n      <td>748.155138</td>\n      <td>0.999830</td>\n      <td>166.376002</td>\n      <td>-1.340407e-05</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>146212</td>\n      <td>0.999998</td>\n      <td>30.165969</td>\n      <td>0.999994</td>\n      <td>9.906997</td>\n      <td>-4.460343e-06</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>167119</td>\n      <td>0.969022</td>\n      <td>34.102057</td>\n      <td>0.975924</td>\n      <td>11.336961</td>\n      <td>6.901951e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>167125</td>\n      <td>0.962805</td>\n      <td>64.667999</td>\n      <td>0.968047</td>\n      <td>16.358957</td>\n      <td>5.242060e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>168336</td>\n      <td>0.735831</td>\n      <td>170.242889</td>\n      <td>0.738881</td>\n      <td>68.541956</td>\n      <td>3.049183e-03</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    3. Taskwise regression - using XGBoost Regressor as EPM for each of the 94 datasets. Each regressor is optimised with BO\n",
    "    Final predicted AUC for a new dataset is a weighted average of the 94 predictions\n",
    "    This should take 5-10min.\n",
    "\n",
    "    Note: If you want the models to be retrained from scratch you have to:\n",
    "        1) Remove taskwise_models.pkl\n",
    "        2) Remove best_candidates.pkl\n",
    "    This cell should take about an hour.\n",
    "\n",
    "    In you want the exact same results you also have to:\n",
    "        1) Set n_points to 20000\n",
    "        2) Change n_splits=5 and n_iter=10 in taskRegressor.py lines 55,56\n",
    "    This should take about 6 hours. If you remove only best.candidates.pkl the evaluation of the best configuration will be performed in around\n",
    "    an hour (you can lower n_points if this is too long).\n",
    "\"\"\"\n",
    "taskwise_regression_results = evaluate_taskwise_regression(n_points=500)\n",
    "display(taskwise_regression_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from pkl - This will take at least a minute\n",
      "\n",
      "Generating random configurations\n",
      "Selecting the best configuration for each task:\n",
      "Task: 16 time 16:50:34\n",
      "Task: 22 time 16:50:34\n",
      "Task: 31 time 16:50:34\n",
      "Task: 2074 time 16:50:34\n",
      "Task: 2079 time 16:50:34\n",
      "Task: 3493 time 16:50:35\n",
      "Task: 3907 time 16:50:35\n",
      "Task: 3913 time 16:50:35\n",
      "Task: 9950 time 16:50:35\n",
      "Task: 9952 time 16:50:35\n",
      "Task: 9971 time 16:50:36\n",
      "Task: 10106 time 16:50:36\n",
      "Task: 14954 time 16:50:36\n",
      "Task: 14970 time 16:50:36\n",
      "Task: 146212 time 16:50:36\n",
      "Task: 167119 time 16:50:37\n",
      "Task: 167125 time 16:50:37\n",
      "Task: 168336 time 16:50:37\n",
      "Evaluating task with id:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9856388888888888\n",
      "Evaluating task with id:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.960361111111111\n",
      "Evaluating task with id:  31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8233333333333334\n",
      "Evaluating task with id:  2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9890481703882097\n",
      "Evaluating task with id:  2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8946792592052413\n",
      "Evaluating task with id:  3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7511904761904762\n",
      "Evaluating task with id:  3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9120060790273556\n",
      "Evaluating task with id:  3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.8971861471861471\n",
      "Evaluating task with id:  9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9926046239427568\n",
      "Evaluating task with id:  9952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9255984721261813\n",
      "Evaluating task with id:  9971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7030812324929971\n",
      "Evaluating task with id:  10106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9992967651195499\n",
      "Evaluating task with id:  14954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9004207573632539\n",
      "Evaluating task with id:  14970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9998093549878909\n",
      "Evaluating task with id:  146212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9999910288132646\n",
      "Evaluating task with id:  167119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9734353403091157\n",
      "Evaluating task with id:  167125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.9635368485969781\n",
      "Evaluating task with id:  168336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New auc 0.7542456652617961\n"
     ]
    },
    {
     "data": {
      "text/plain": "    task_id  base_auc   base_time   new_auc    new_time     delta_auc  \\\n0        16  0.997222   31.225133  0.985639   25.781999 -1.158333e-02   \n1        22  0.973361   25.774230  0.960361   21.800998 -1.300000e-02   \n2        31  0.841905    1.274992  0.823333    0.327000 -1.857143e-02   \n3      2074  0.989416   18.240999  0.989048   28.071959 -3.677576e-04   \n4      2079  0.915436    3.369999  0.894679    1.858947 -2.075658e-02   \n5      3493  0.976190    0.539915  0.751190    1.489997 -2.250000e-01   \n6      3907  0.985866    2.770957  0.912006    5.294053 -7.386018e-02   \n7      3913  0.906926    0.559001  0.897186    0.143998 -9.740260e-03   \n8      9950  0.996221   32.786961  0.992605   20.840997 -3.615984e-03   \n9      9952  0.956024    2.991995  0.925598    4.319001 -3.042576e-02   \n10     9971  0.668067    0.624963  0.703081    1.645998  3.501401e-02   \n11    10106  0.999297    9.776999  0.999297    9.508999 -1.110223e-16   \n12    14954  0.910238    0.831042  0.900421    0.943004 -9.817672e-03   \n13    14970  0.999844  748.155138  0.999809  647.496241 -3.428626e-05   \n14   146212  0.999998   30.165969  0.999991   82.876001 -7.391822e-06   \n15   167119  0.969022   34.102057  0.973435   34.224999  4.413401e-03   \n16   167125  0.962805   64.667999  0.963537   17.729996  7.323466e-04   \n17   168336  0.735831  170.242889  0.754246   86.113999  1.841427e-02   \n\n    better_auc  better_time  \n0        False         True  \n1        False         True  \n2        False         True  \n3        False        False  \n4        False         True  \n5        False        False  \n6        False        False  \n7        False         True  \n8        False         True  \n9        False        False  \n10        True        False  \n11       False         True  \n12       False        False  \n13       False         True  \n14       False        False  \n15        True        False  \n16        True         True  \n17        True         True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>base_auc</th>\n      <th>base_time</th>\n      <th>new_auc</th>\n      <th>new_time</th>\n      <th>delta_auc</th>\n      <th>better_auc</th>\n      <th>better_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>0.997222</td>\n      <td>31.225133</td>\n      <td>0.985639</td>\n      <td>25.781999</td>\n      <td>-1.158333e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>0.973361</td>\n      <td>25.774230</td>\n      <td>0.960361</td>\n      <td>21.800998</td>\n      <td>-1.300000e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31</td>\n      <td>0.841905</td>\n      <td>1.274992</td>\n      <td>0.823333</td>\n      <td>0.327000</td>\n      <td>-1.857143e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2074</td>\n      <td>0.989416</td>\n      <td>18.240999</td>\n      <td>0.989048</td>\n      <td>28.071959</td>\n      <td>-3.677576e-04</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2079</td>\n      <td>0.915436</td>\n      <td>3.369999</td>\n      <td>0.894679</td>\n      <td>1.858947</td>\n      <td>-2.075658e-02</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3493</td>\n      <td>0.976190</td>\n      <td>0.539915</td>\n      <td>0.751190</td>\n      <td>1.489997</td>\n      <td>-2.250000e-01</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3907</td>\n      <td>0.985866</td>\n      <td>2.770957</td>\n      <td>0.912006</td>\n      <td>5.294053</td>\n      <td>-7.386018e-02</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3913</td>\n      <td>0.906926</td>\n      <td>0.559001</td>\n      <td>0.897186</td>\n      <td>0.143998</td>\n      <td>-9.740260e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9950</td>\n      <td>0.996221</td>\n      <td>32.786961</td>\n      <td>0.992605</td>\n      <td>20.840997</td>\n      <td>-3.615984e-03</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9952</td>\n      <td>0.956024</td>\n      <td>2.991995</td>\n      <td>0.925598</td>\n      <td>4.319001</td>\n      <td>-3.042576e-02</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9971</td>\n      <td>0.668067</td>\n      <td>0.624963</td>\n      <td>0.703081</td>\n      <td>1.645998</td>\n      <td>3.501401e-02</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>10106</td>\n      <td>0.999297</td>\n      <td>9.776999</td>\n      <td>0.999297</td>\n      <td>9.508999</td>\n      <td>-1.110223e-16</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>14954</td>\n      <td>0.910238</td>\n      <td>0.831042</td>\n      <td>0.900421</td>\n      <td>0.943004</td>\n      <td>-9.817672e-03</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14970</td>\n      <td>0.999844</td>\n      <td>748.155138</td>\n      <td>0.999809</td>\n      <td>647.496241</td>\n      <td>-3.428626e-05</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>146212</td>\n      <td>0.999998</td>\n      <td>30.165969</td>\n      <td>0.999991</td>\n      <td>82.876001</td>\n      <td>-7.391822e-06</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>167119</td>\n      <td>0.969022</td>\n      <td>34.102057</td>\n      <td>0.973435</td>\n      <td>34.224999</td>\n      <td>4.413401e-03</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>167125</td>\n      <td>0.962805</td>\n      <td>64.667999</td>\n      <td>0.963537</td>\n      <td>17.729996</td>\n      <td>7.323466e-04</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>168336</td>\n      <td>0.735831</td>\n      <td>170.242889</td>\n      <td>0.754246</td>\n      <td>86.113999</td>\n      <td>1.841427e-02</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    4. Joint regression - using XGBoost Regressor as EPM to jointly model (metafeatures, hyperparameters) => AUC\n",
    "\n",
    "    Note: If you want the model to be retrained from scratch:\n",
    "        1) Remove full_data_xgboost_regressors.pkl\n",
    "    Also, the fraction of data used was lowered to 5% and the number of BO iterations to 10.\n",
    "    Without changing the parameters this should take 30-45mins.\n",
    "\n",
    "    If you want the same results seen above you need to set:\n",
    "        1) fraction = 0.15\n",
    "        2) n_iter = 20\n",
    "        3) n_points = 200000\n",
    "    In that case the following function call will take around 2 hours.\n",
    "\n",
    "    If you just want to run the evaluation no changes need to be made. Lowering n_points will speedup the evaluation.\n",
    "    Otherwise it should take 10-15min.\n",
    "\"\"\"\n",
    "joint_regresssion_results = evaluate_full_data_regression(save_address=\"./fulldata_nested_xgboost_results.csv\", n_points=50000,\n",
    "                                                          use_gaussian = False, fraction=0.05, n_iter=10)\n",
    "display(joint_regresssion_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}